from Jade require "common/keccak/common/fips202_DIRTY.jinc"
from Jade require "common/keccak/common/fips202_4x_DIRTY.jinc"
from Jade require "crypto_xof/shake128/amd64/avx2/shake128_4x.jinc"

param int GENMATRIX_NBLOCKS = ((12*KYBER_N/8*4096/KYBER_Q + SHAKE128_RATE)/SHAKE128_RATE);
param int REJ_UNIFORM_AVX_BUFLEN = GENMATRIX_NBLOCKS * SHAKE128_RATE;

u8[2048] ru_idx = {-1, -1, -1, -1, -1, -1, -1, -1,
                0, -1, -1, -1, -1, -1, -1, -1,
                2, -1, -1, -1, -1, -1, -1, -1,
                0,  2, -1, -1, -1, -1, -1, -1,
                4, -1, -1, -1, -1, -1, -1, -1,
                0,  4, -1, -1, -1, -1, -1, -1,
                2,  4, -1, -1, -1, -1, -1, -1,
                0,  2,  4, -1, -1, -1, -1, -1,
                6, -1, -1, -1, -1, -1, -1, -1,
                0,  6, -1, -1, -1, -1, -1, -1,
                2,  6, -1, -1, -1, -1, -1, -1,
                0,  2,  6, -1, -1, -1, -1, -1,
                4,  6, -1, -1, -1, -1, -1, -1,
                0,  4,  6, -1, -1, -1, -1, -1,
                2,  4,  6, -1, -1, -1, -1, -1,
                0,  2,  4,  6, -1, -1, -1, -1,
                8, -1, -1, -1, -1, -1, -1, -1,
                0,  8, -1, -1, -1, -1, -1, -1,
                2,  8, -1, -1, -1, -1, -1, -1,
                0,  2,  8, -1, -1, -1, -1, -1,
                4,  8, -1, -1, -1, -1, -1, -1,
                0,  4,  8, -1, -1, -1, -1, -1,
                2,  4,  8, -1, -1, -1, -1, -1,
                0,  2,  4,  8, -1, -1, -1, -1,
                6,  8, -1, -1, -1, -1, -1, -1,
                0,  6,  8, -1, -1, -1, -1, -1,
                2,  6,  8, -1, -1, -1, -1, -1,
                0,  2,  6,  8, -1, -1, -1, -1,
                4,  6,  8, -1, -1, -1, -1, -1,
                0,  4,  6,  8, -1, -1, -1, -1,
                2,  4,  6,  8, -1, -1, -1, -1,
                0,  2,  4,  6,  8, -1, -1, -1,
                10, -1, -1, -1, -1, -1, -1, -1,
                0, 10, -1, -1, -1, -1, -1, -1,
                2, 10, -1, -1, -1, -1, -1, -1,
                0,  2, 10, -1, -1, -1, -1, -1,
                4, 10, -1, -1, -1, -1, -1, -1,
                0,  4, 10, -1, -1, -1, -1, -1,
                2,  4, 10, -1, -1, -1, -1, -1,
                0,  2,  4, 10, -1, -1, -1, -1,
                6, 10, -1, -1, -1, -1, -1, -1,
                0,  6, 10, -1, -1, -1, -1, -1,
                2,  6, 10, -1, -1, -1, -1, -1,
                0,  2,  6, 10, -1, -1, -1, -1,
                4,  6, 10, -1, -1, -1, -1, -1,
                0,  4,  6, 10, -1, -1, -1, -1,
                2,  4,  6, 10, -1, -1, -1, -1,
                0,  2,  4,  6, 10, -1, -1, -1,
                8, 10, -1, -1, -1, -1, -1, -1,
                0,  8, 10, -1, -1, -1, -1, -1,
                2,  8, 10, -1, -1, -1, -1, -1,
                0,  2,  8, 10, -1, -1, -1, -1,
                4,  8, 10, -1, -1, -1, -1, -1,
                0,  4,  8, 10, -1, -1, -1, -1,
                2,  4,  8, 10, -1, -1, -1, -1,
                0,  2,  4,  8, 10, -1, -1, -1,
                6,  8, 10, -1, -1, -1, -1, -1,
                0,  6,  8, 10, -1, -1, -1, -1,
                2,  6,  8, 10, -1, -1, -1, -1,
                0,  2,  6,  8, 10, -1, -1, -1,
                4,  6,  8, 10, -1, -1, -1, -1,
                0,  4,  6,  8, 10, -1, -1, -1,
                2,  4,  6,  8, 10, -1, -1, -1,
                0,  2,  4,  6,  8, 10, -1, -1,
                12, -1, -1, -1, -1, -1, -1, -1,
                0, 12, -1, -1, -1, -1, -1, -1,
                2, 12, -1, -1, -1, -1, -1, -1,
                0,  2, 12, -1, -1, -1, -1, -1,
                4, 12, -1, -1, -1, -1, -1, -1,
                0,  4, 12, -1, -1, -1, -1, -1,
                2,  4, 12, -1, -1, -1, -1, -1,
                0,  2,  4, 12, -1, -1, -1, -1,
                6, 12, -1, -1, -1, -1, -1, -1,
                0,  6, 12, -1, -1, -1, -1, -1,
                2,  6, 12, -1, -1, -1, -1, -1,
                0,  2,  6, 12, -1, -1, -1, -1,
                4,  6, 12, -1, -1, -1, -1, -1,
                0,  4,  6, 12, -1, -1, -1, -1,
                2,  4,  6, 12, -1, -1, -1, -1,
                0,  2,  4,  6, 12, -1, -1, -1,
                8, 12, -1, -1, -1, -1, -1, -1,
                0,  8, 12, -1, -1, -1, -1, -1,
                2,  8, 12, -1, -1, -1, -1, -1,
                0,  2,  8, 12, -1, -1, -1, -1,
                4,  8, 12, -1, -1, -1, -1, -1,
                0,  4,  8, 12, -1, -1, -1, -1,
                2,  4,  8, 12, -1, -1, -1, -1,
                0,  2,  4,  8, 12, -1, -1, -1,
                6,  8, 12, -1, -1, -1, -1, -1,
                0,  6,  8, 12, -1, -1, -1, -1,
                2,  6,  8, 12, -1, -1, -1, -1,
                0,  2,  6,  8, 12, -1, -1, -1,
                4,  6,  8, 12, -1, -1, -1, -1,
                0,  4,  6,  8, 12, -1, -1, -1,
                2,  4,  6,  8, 12, -1, -1, -1,
                0,  2,  4,  6,  8, 12, -1, -1,
                10, 12, -1, -1, -1, -1, -1, -1,
                0, 10, 12, -1, -1, -1, -1, -1,
                2, 10, 12, -1, -1, -1, -1, -1,
                0,  2, 10, 12, -1, -1, -1, -1,
                4, 10, 12, -1, -1, -1, -1, -1,
                0,  4, 10, 12, -1, -1, -1, -1,
                2,  4, 10, 12, -1, -1, -1, -1,
                0,  2,  4, 10, 12, -1, -1, -1,
                6, 10, 12, -1, -1, -1, -1, -1,
                0,  6, 10, 12, -1, -1, -1, -1,
                2,  6, 10, 12, -1, -1, -1, -1,
                0,  2,  6, 10, 12, -1, -1, -1,
                4,  6, 10, 12, -1, -1, -1, -1,
                0,  4,  6, 10, 12, -1, -1, -1,
                2,  4,  6, 10, 12, -1, -1, -1,
                0,  2,  4,  6, 10, 12, -1, -1,
                8, 10, 12, -1, -1, -1, -1, -1,
                0,  8, 10, 12, -1, -1, -1, -1,
                2,  8, 10, 12, -1, -1, -1, -1,
                0,  2,  8, 10, 12, -1, -1, -1,
                4,  8, 10, 12, -1, -1, -1, -1,
                0,  4,  8, 10, 12, -1, -1, -1,
                2,  4,  8, 10, 12, -1, -1, -1,
                0,  2,  4,  8, 10, 12, -1, -1,
                6,  8, 10, 12, -1, -1, -1, -1,
                0,  6,  8, 10, 12, -1, -1, -1,
                2,  6,  8, 10, 12, -1, -1, -1,
                0,  2,  6,  8, 10, 12, -1, -1,
                4,  6,  8, 10, 12, -1, -1, -1,
                0,  4,  6,  8, 10, 12, -1, -1,
                2,  4,  6,  8, 10, 12, -1, -1,
                0,  2,  4,  6,  8, 10, 12, -1,
                14, -1, -1, -1, -1, -1, -1, -1,
                0, 14, -1, -1, -1, -1, -1, -1,
                2, 14, -1, -1, -1, -1, -1, -1,
                0,  2, 14, -1, -1, -1, -1, -1,
                4, 14, -1, -1, -1, -1, -1, -1,
                0,  4, 14, -1, -1, -1, -1, -1,
                2,  4, 14, -1, -1, -1, -1, -1,
                0,  2,  4, 14, -1, -1, -1, -1,
                6, 14, -1, -1, -1, -1, -1, -1,
                0,  6, 14, -1, -1, -1, -1, -1,
                2,  6, 14, -1, -1, -1, -1, -1,
                0,  2,  6, 14, -1, -1, -1, -1,
                4,  6, 14, -1, -1, -1, -1, -1,
                0,  4,  6, 14, -1, -1, -1, -1,
                2,  4,  6, 14, -1, -1, -1, -1,
                0,  2,  4,  6, 14, -1, -1, -1,
                8, 14, -1, -1, -1, -1, -1, -1,
                0,  8, 14, -1, -1, -1, -1, -1,
                2,  8, 14, -1, -1, -1, -1, -1,
                0,  2,  8, 14, -1, -1, -1, -1,
                4,  8, 14, -1, -1, -1, -1, -1,
                0,  4,  8, 14, -1, -1, -1, -1,
                2,  4,  8, 14, -1, -1, -1, -1,
                0,  2,  4,  8, 14, -1, -1, -1,
                6,  8, 14, -1, -1, -1, -1, -1,
                0,  6,  8, 14, -1, -1, -1, -1,
                2,  6,  8, 14, -1, -1, -1, -1,
                0,  2,  6,  8, 14, -1, -1, -1,
                4,  6,  8, 14, -1, -1, -1, -1,
                0,  4,  6,  8, 14, -1, -1, -1,
                2,  4,  6,  8, 14, -1, -1, -1,
                0,  2,  4,  6,  8, 14, -1, -1,
                10, 14, -1, -1, -1, -1, -1, -1,
                0, 10, 14, -1, -1, -1, -1, -1,
                2, 10, 14, -1, -1, -1, -1, -1,
                0,  2, 10, 14, -1, -1, -1, -1,
                4, 10, 14, -1, -1, -1, -1, -1,
                0,  4, 10, 14, -1, -1, -1, -1,
                2,  4, 10, 14, -1, -1, -1, -1,
                0,  2,  4, 10, 14, -1, -1, -1,
                6, 10, 14, -1, -1, -1, -1, -1,
                0,  6, 10, 14, -1, -1, -1, -1,
                2,  6, 10, 14, -1, -1, -1, -1,
                0,  2,  6, 10, 14, -1, -1, -1,
                4,  6, 10, 14, -1, -1, -1, -1,
                0,  4,  6, 10, 14, -1, -1, -1,
                2,  4,  6, 10, 14, -1, -1, -1,
                0,  2,  4,  6, 10, 14, -1, -1,
                8, 10, 14, -1, -1, -1, -1, -1,
                0,  8, 10, 14, -1, -1, -1, -1,
                2,  8, 10, 14, -1, -1, -1, -1,
                0,  2,  8, 10, 14, -1, -1, -1,
                4,  8, 10, 14, -1, -1, -1, -1,
                0,  4,  8, 10, 14, -1, -1, -1,
                2,  4,  8, 10, 14, -1, -1, -1,
                0,  2,  4,  8, 10, 14, -1, -1,
                6,  8, 10, 14, -1, -1, -1, -1,
                0,  6,  8, 10, 14, -1, -1, -1,
                2,  6,  8, 10, 14, -1, -1, -1,
                0,  2,  6,  8, 10, 14, -1, -1,
                4,  6,  8, 10, 14, -1, -1, -1,
                0,  4,  6,  8, 10, 14, -1, -1,
                2,  4,  6,  8, 10, 14, -1, -1,
                0,  2,  4,  6,  8, 10, 14, -1,
                12, 14, -1, -1, -1, -1, -1, -1,
                0, 12, 14, -1, -1, -1, -1, -1,
                2, 12, 14, -1, -1, -1, -1, -1,
                0,  2, 12, 14, -1, -1, -1, -1,
                4, 12, 14, -1, -1, -1, -1, -1,
                0,  4, 12, 14, -1, -1, -1, -1,
                2,  4, 12, 14, -1, -1, -1, -1,
                0,  2,  4, 12, 14, -1, -1, -1,
                6, 12, 14, -1, -1, -1, -1, -1,
                0,  6, 12, 14, -1, -1, -1, -1,
                2,  6, 12, 14, -1, -1, -1, -1,
                0,  2,  6, 12, 14, -1, -1, -1,
                4,  6, 12, 14, -1, -1, -1, -1,
                0,  4,  6, 12, 14, -1, -1, -1,
                2,  4,  6, 12, 14, -1, -1, -1,
                0,  2,  4,  6, 12, 14, -1, -1,
                8, 12, 14, -1, -1, -1, -1, -1,
                0,  8, 12, 14, -1, -1, -1, -1,
                2,  8, 12, 14, -1, -1, -1, -1,
                0,  2,  8, 12, 14, -1, -1, -1,
                4,  8, 12, 14, -1, -1, -1, -1,
                0,  4,  8, 12, 14, -1, -1, -1,
                2,  4,  8, 12, 14, -1, -1, -1,
                0,  2,  4,  8, 12, 14, -1, -1,
                6,  8, 12, 14, -1, -1, -1, -1,
                0,  6,  8, 12, 14, -1, -1, -1,
                2,  6,  8, 12, 14, -1, -1, -1,
                0,  2,  6,  8, 12, 14, -1, -1,
                4,  6,  8, 12, 14, -1, -1, -1,
                0,  4,  6,  8, 12, 14, -1, -1,
                2,  4,  6,  8, 12, 14, -1, -1,
                0,  2,  4,  6,  8, 12, 14, -1,
                10, 12, 14, -1, -1, -1, -1, -1,
                0, 10, 12, 14, -1, -1, -1, -1,
                2, 10, 12, 14, -1, -1, -1, -1,
                0,  2, 10, 12, 14, -1, -1, -1,
                4, 10, 12, 14, -1, -1, -1, -1,
                0,  4, 10, 12, 14, -1, -1, -1,
                2,  4, 10, 12, 14, -1, -1, -1,
                0,  2,  4, 10, 12, 14, -1, -1,
                6, 10, 12, 14, -1, -1, -1, -1,
                0,  6, 10, 12, 14, -1, -1, -1,
                2,  6, 10, 12, 14, -1, -1, -1,
                0,  2,  6, 10, 12, 14, -1, -1,
                4,  6, 10, 12, 14, -1, -1, -1,
                0,  4,  6, 10, 12, 14, -1, -1,
                2,  4,  6, 10, 12, 14, -1, -1,
                0,  2,  4,  6, 10, 12, 14, -1,
                8, 10, 12, 14, -1, -1, -1, -1,
                0,  8, 10, 12, 14, -1, -1, -1,
                2,  8, 10, 12, 14, -1, -1, -1,
                0,  2,  8, 10, 12, 14, -1, -1,
                4,  8, 10, 12, 14, -1, -1, -1,
                0,  4,  8, 10, 12, 14, -1, -1,
                2,  4,  8, 10, 12, 14, -1, -1,
                0,  2,  4,  8, 10, 12, 14, -1,
                6,  8, 10, 12, 14, -1, -1, -1,
                0,  6,  8, 10, 12, 14, -1, -1,
                2,  6,  8, 10, 12, 14, -1, -1,
                0,  2,  6,  8, 10, 12, 14, -1,
                4,  6,  8, 10, 12, 14, -1, -1,
                0,  4,  6,  8, 10, 12, 14, -1,
                2,  4,  6,  8, 10, 12, 14, -1,
                0,  2,  4,  6,  8, 10, 12, 14};

inline
fn __shake128_squeezenblocks4x(reg ptr u256[25] state, reg ptr u8[REJ_UNIFORM_AVX_BUFLEN] h0 h1 h2 h3)
  -> reg ptr u256[25], reg ptr u8[REJ_UNIFORM_AVX_BUFLEN], reg ptr u8[REJ_UNIFORM_AVX_BUFLEN], reg ptr u8[REJ_UNIFORM_AVX_BUFLEN], reg ptr u8[REJ_UNIFORM_AVX_BUFLEN]
{
  inline int i;

  for i = 0 to GENMATRIX_NBLOCKS
  {
    state, h0[i*SHAKE128_RATE:SHAKE128_RATE], h1[i*SHAKE128_RATE:SHAKE128_RATE], h2[i*SHAKE128_RATE:SHAKE128_RATE], h3[i*SHAKE128_RATE:SHAKE128_RATE] = __shake128_squeezeblock4x(state, h0[i*SHAKE128_RATE:SHAKE128_RATE], h1[i*SHAKE128_RATE:SHAKE128_RATE], h2[i*SHAKE128_RATE:SHAKE128_RATE], h3[i*SHAKE128_RATE:SHAKE128_RATE]);
  }

  return state, h0, h1, h2, h3;
}

inline
fn __rej_uniform(reg ptr u16[KYBER_N] rp, reg u64 offset, reg ptr u8[SHAKE128_RATE] buf, inline int buflen) ->  reg u64, stack u16[KYBER_N]
{
  reg u16 val0 val1;
  reg u16 t;
  reg u64 pos ctr;
  reg u8 fl1 fl2;
  reg bool cf zf b;

  ctr = offset;
  pos = 0;

  _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 1);
  fl1 = #SETcc(cf || zf); //SETBE

  _, cf, _, _, zf = #CMP_64(pos, buflen - 3);
  fl2 = #SETcc(cf || zf);  //SETBE

  _, _, _, _, b = #TEST_8(fl1, fl2);

  while(!b)
  {
    val0 = (16u)buf[(int)pos];
    pos += 1;

    t   = (16u)buf[(int)pos];
    val1 = t;
    val1 >>= 4;

    t &= 0x0F;
    t <<= 8;
    val0 |= t;
    pos += 1;

    t   = (16u)buf[(int)pos];
    t <<= 4;
    val1 |= t;
    pos += 1;

    if(val0 < KYBER_Q)
    {
      rp[(int)ctr] = val0;
      ctr += 1;
    }

    if(ctr < KYBER_N)
    {
      if(val1 < KYBER_Q)
      {
        rp[(int)ctr] = val1;
        ctr += 1;
      }
    }

    _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 1);
    fl1 = #SETcc(cf || zf); //SETBE

    _, cf, _, _, zf = #CMP_64(pos, buflen - 3);
    fl2 = #SETcc(cf || zf);  //SETBE

    _, _, _, _, b = #TEST_8(fl1, fl2);
  }

  return ctr, rp;
}

u8 ru_ones_s = 1;
u16 ru_mask_s = 0x0FFF;
u8[32] ru_idx8_s = {0, 1, 1, 2, 3, 4, 4, 5,
                 6, 7, 7, 8, 9, 10, 10, 11,
                 4, 5, 5, 6, 7, 8, 8, 9,
                 10, 11, 11, 12, 13, 14, 14, 15};

fn _rej_uniform_avx(reg ptr u16[KYBER_N] rp, reg ptr u8[REJ_UNIFORM_AVX_BUFLEN] buf) -> reg u64, reg ptr u16[KYBER_N]
{
  reg u256 f0 f1 g0 g1 g2 g3;
  reg u256 bound ones mask idx8;
  reg u128 f t l h;
  reg u64 pos ctr t64 t64_1 t64_2 t64_3;
  reg u64 good;
  reg u16 val0 val1 t16;
  reg ptr u8[2048] idxp;
  reg u8 fl1 fl2;
  reg bool cf zf b;

  idxp = ru_idx;

  bound = jqx16[u256 0];
  ctr = 0;
  pos = 0;
  ones = #VPBROADCAST_32u8(ru_ones_s);
  mask = #VPBROADCAST_16u16(ru_mask_s);
  idx8 = ru_idx8_s[u256 0];

  _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 32);
  fl1 = #SETcc(cf || zf);

  _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 56);
  fl2 = #SETcc(cf || zf);

   _, _, _, _, b = #TEST_8(fl1, fl2);

  while(!b)
  {
    f0 = #VPERMQ(buf.[u256 (int)pos], 0x94);
    f1 = #VPERMQ(buf.[u256 24 + (int)pos], 0x94);
    f0 = #VPSHUFB_256(f0, idx8);
    f1 = #VPSHUFB_256(f1, idx8);
    g0 = #VPSRL_16u16(f0, 4);
    g1 = #VPSRL_16u16(f1, 4);
    f0 = #VPBLEND_16u16(f0, g0, 0xAA);
    f1 = #VPBLEND_16u16(f1, g1, 0xAA);
    f0 = #VPAND_256(f0, mask);
    f1 = #VPAND_256(f1, mask);

    g0 = #VPCMPGT_16u16(bound, f0);
    g1 = #VPCMPGT_16u16(bound, f1);

    g0 = #VPACKSS_16u16(g0, g1);
    good = #VPMOVMSKB_u256u64(g0);

    t64 = good;
    t64 &= 0xFF;
    g0 = (256u) #VMOV(idxp[u64 (int)t64]);

    t64_1 = good;
    t64_1 >>= 16;
    t64_1 &= 0xFF;
    l = #VMOV(idxp[u64 (int)t64_1]);

    t64_2 = good;
    t64_2 >>= 8;
    t64_2 &= 0xFF;
    g1 = (256u) #VMOV(idxp[u64 (int)t64_2]);

    t64_3 = good;
    t64_3 >>= 24;
    t64_3 &= 0xFF;
    h = #VMOV(idxp[u64 (int)t64_3]);

    g0 = #VINSERTI128(g0, l, 1);

    _, _, _, _, _, t64 = #POPCNT_64(t64);
    _, _, _, _, _, t64_1 = #POPCNT_64(t64_1);
    t64 += ctr;

    g1 = #VINSERTI128(g1, h, 1);

    t64_1 += t64;
    _, _, _, _, _, t64_2 = #POPCNT_64(t64_2);
    t64_2 += t64_1;
    _, _, _, _, _, t64_3 = #POPCNT_64(t64_3);
    t64_3 += t64_2;

    g2 = #VPADD_32u8(g0, ones);
    g0 = #VPUNPCKL_32u8(g0, g2);
    g3 = #VPADD_32u8(g1, ones);
    g1 = #VPUNPCKL_32u8(g1, g3);

    f0 = #VPSHUFB_256(f0, g0);
    f1 = #VPSHUFB_256(f1, g1);

    rp.[u128 2*(int)ctr] = (128u)f0;
    rp.[u128 2*(int)t64] = #VEXTRACTI128(f0, 1);
    rp.[u128 2*(int)t64_1] = (128u)f1;
    rp.[u128 2*(int)t64_2] = #VEXTRACTI128(f1, 1);

    ctr = t64_3;

    _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 32);
    fl1 = #SETcc(cf || zf);

    pos += 48;
    _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 56);
    fl2 = #SETcc(cf || zf);

     _, _, _, _, b = #TEST_8(fl1, fl2);
  }

  _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 8);
  fl1 = #SETcc(cf || zf);

  _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 16);
  fl2 = #SETcc(cf || zf);

   _, _, _, _, b = #TEST_8(fl1, fl2);

  t64 = 0x5555;
  while(!b)
  {
    f = buf.[u128 (int)pos];
    f = #VPSHUFB_128(f, idx8);
    t = #VPSRL_8u16(f, 4);
    f = #VPBLEND_8u16(f, t, 0xAA);
    f = #VPAND_128(f, mask);

    t = #VPCMPGT_8u16(bound, f);
    good = #VPMOVMSKB_u128u64(t);

    good = #PEXT_64(good, t64);
    l = #VMOV(idxp[u64 (int)good]);
    _, _, _, _, _, good =  #POPCNT_64(good);

    h = #VPADD_16u8(l, ones);
    l = #VPUNPCKL_16u8(l, h);
    f = #VPSHUFB_128(f, l);

    rp.[u128 2*(int)ctr] = f;
    ctr += good;

    pos += 12;
    _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 8);
    fl1 = #SETcc(cf || zf);

    _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 16);
    fl2 = #SETcc(cf || zf);

     _, _, _, _, b = #TEST_8(fl1, fl2);
  }

  _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 1);
  fl1 = #SETcc(cf || zf);

  _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 3);
  fl2 = #SETcc(cf || zf);

   _, _, _, _, b = #TEST_8(fl1, fl2);

  while(!b)
  {
    val0 = (16u)buf[(int)pos];
    pos += 1;
    t16 = (16u)buf[(int)pos];
    pos += 1;
    val1 = t16;

    t16 <<= 8;
    val0 |= t16;
    val0 &= 0xFFF;

    val1 >>= 4;
    t16 = (16u)buf[(int)pos];
    pos += 1;
    t16 <<= 4;
    val1 |= t16;

    if(val0 < KYBER_Q)
    {
      rp[(int)ctr] = val0;
      ctr += 1;
    }
    if(val1 < KYBER_Q)
    {
      if(ctr < KYBER_N)
      {
        rp[(int)ctr] = val1;
        ctr += 1;
      }
    }

    _, cf, _, _, zf = #CMP_64(ctr, KYBER_N - 1);
    fl1 = #SETcc(cf || zf); //SETBE

    _, cf, _, _, zf = #CMP_64(pos, REJ_UNIFORM_AVX_BUFLEN - 3);
    fl2 = #SETcc(cf || zf);  //SETBE

    _, _, _, _, b = #TEST_8(fl1, fl2);
  }

  return ctr, rp;
}

inline
fn __gen_matrix(stack u8[KYBER_SYMBYTES] seed, inline int transposed) -> stack u16[KYBER_K*KYBER_VECN]
{
  stack u8[REJ_UNIFORM_AVX_BUFLEN] buf0;
  stack u8[REJ_UNIFORM_AVX_BUFLEN] buf1;
  stack u8[REJ_UNIFORM_AVX_BUFLEN] buf2;
  stack u8[REJ_UNIFORM_AVX_BUFLEN] buf3;
  stack u256[25] state;
  stack u16[KYBER_K*KYBER_VECN] rr;
  reg u256 f;
  reg u64 ctr0 ctr1 ctr2 ctr3 tmp;
  reg u8 flg0 flg1 bflg;
  reg bool cf zf;
  inline int i, j;
  
  f = seed[u256 0];
  buf0[u256 0] = f;
  buf1[u256 0] = f;
  buf2[u256 0] = f;
  buf3[u256 0] = f;

  if(transposed == 1)
  {
    buf0[KYBER_SYMBYTES]   = 0;
    buf0[KYBER_SYMBYTES+1] = 0;
    buf1[KYBER_SYMBYTES]   = 0;
    buf1[KYBER_SYMBYTES+1] = 1;
    buf2[KYBER_SYMBYTES]   = 1;
    buf2[KYBER_SYMBYTES+1] = 0;
    buf3[KYBER_SYMBYTES]   = 1;
    buf3[KYBER_SYMBYTES+1] = 1;
  }
  else
  {
    buf0[KYBER_SYMBYTES]   = 0;
    buf0[KYBER_SYMBYTES+1] = 0;
    buf1[KYBER_SYMBYTES]   = 1;
    buf1[KYBER_SYMBYTES+1] = 0;
    buf2[KYBER_SYMBYTES]   = 0;
    buf2[KYBER_SYMBYTES+1] = 1;
    buf3[KYBER_SYMBYTES]   = 1;
    buf3[KYBER_SYMBYTES+1] = 1;
  }

  state = _shake128_absorb4x_34(state, buf0[0:34], buf1[0:34], buf2[0:34], buf3[0:34]);
  state, buf0, buf1, buf2, buf3 = __shake128_squeezenblocks4x(state, buf0, buf1, buf2, buf3);

  tmp, rr[0*KYBER_VECN+0*KYBER_N:KYBER_N] = _rej_uniform_avx(rr[0*KYBER_VECN+0*KYBER_N:KYBER_N], buf0);
  ctr0 = tmp;
  tmp, rr[0*KYBER_VECN+1*KYBER_N:KYBER_N] = _rej_uniform_avx(rr[0*KYBER_VECN+1*KYBER_N:KYBER_N], buf1);
  ctr1 = tmp;
  tmp, rr[1*KYBER_VECN+0*KYBER_N:KYBER_N] = _rej_uniform_avx(rr[1*KYBER_VECN+0*KYBER_N:KYBER_N], buf2);
  ctr2 = tmp;
  ctr3, rr[1*KYBER_VECN+1*KYBER_N:KYBER_N] = _rej_uniform_avx(rr[1*KYBER_VECN+1*KYBER_N:KYBER_N], buf3);

  _, cf, _, _, zf = #CMP_64(ctr0, KYBER_N - 1);
  flg0 = #SETcc(cf || zf); //SETBE

  _, cf, _, _, zf = #CMP_64(ctr1, KYBER_N - 1);
  flg1 = #SETcc(cf || zf);

  _, _, _, _, _, bflg = #OR_8(flg0, flg1);

  _, cf, _, _, zf = #CMP_64(ctr2, KYBER_N - 1);
  flg0 = #SETcc(cf || zf);

  _, cf, _, _, zf = #CMP_64(ctr3, KYBER_N - 1);
  flg1 = #SETcc(cf || zf);

  _, _, _, _, _, flg0 = #OR_8(flg0, flg1);
  _, _, _, _, _, bflg = #OR_8(flg0, bflg);

  while(bflg != 0) {
    state, buf0[0:SHAKE128_RATE], buf1[0:SHAKE128_RATE], buf2[0:SHAKE128_RATE], buf3[0:SHAKE128_RATE] = __shake128_squeezeblock4x(state, buf0[0:SHAKE128_RATE], buf1[0:SHAKE128_RATE], buf2[0:SHAKE128_RATE], buf3[0:SHAKE128_RATE]);

    ctr0, rr[0*KYBER_VECN+0*KYBER_N:KYBER_N] = __rej_uniform(rr[0*KYBER_VECN+0*KYBER_N:KYBER_N], ctr0, buf0[0:SHAKE128_RATE], SHAKE128_RATE);
    ctr1, rr[0*KYBER_VECN+1*KYBER_N:KYBER_N] = __rej_uniform(rr[0*KYBER_VECN+1*KYBER_N:KYBER_N], ctr1, buf1[0:SHAKE128_RATE], SHAKE128_RATE);
    ctr2, rr[1*KYBER_VECN+0*KYBER_N:KYBER_N] = __rej_uniform(rr[1*KYBER_VECN+0*KYBER_N:KYBER_N], ctr2, buf2[0:SHAKE128_RATE], SHAKE128_RATE);
    ctr3, rr[1*KYBER_VECN+1*KYBER_N:KYBER_N] = __rej_uniform(rr[1*KYBER_VECN+1*KYBER_N:KYBER_N], ctr3, buf3[0:SHAKE128_RATE], SHAKE128_RATE);

    _, cf, _, _, zf = #CMP_64(ctr0, KYBER_N - 1);
    flg0 = #SETcc(cf || zf);

    _, cf, _, _, zf = #CMP_64(ctr1, KYBER_N - 1);
    flg1 = #SETcc(cf || zf);

    _, _, _, _, _, bflg = #OR_8(flg0, flg1);

    _, cf, _, _, zf = #CMP_64(ctr2, KYBER_N - 1);
    flg0 = #SETcc(cf || zf);

    _, cf, _, _, zf = #CMP_64(ctr3, KYBER_N - 1);
    flg1 = #SETcc(cf || zf);

    _, _, _, _, _, flg0 = #OR_8(flg0, flg1);
    _, _, _, _, _, bflg = #OR_8(flg0, bflg);
  }
  for i = 0 to KYBER_K
  {
    for j = 0 to KYBER_K
    {
      rr[i*KYBER_VECN+j*KYBER_N:KYBER_N] = _nttunpack(rr[i*KYBER_VECN+j*KYBER_N:KYBER_N]);
    }
  }


  return rr;
}
